{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "68a38e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import skew\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "15b24a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"F:/HAR/DSADS/features2.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9837bf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.18320</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>6.267229e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.21290</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>7.403458e-07</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.21280</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802523e-07</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.31700</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>5.398837e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.25740</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.787533e-07</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>9.298029</td>\n",
       "      <td>32.4980</td>\n",
       "      <td>-6.0782</td>\n",
       "      <td>134.634624</td>\n",
       "      <td>11.603216</td>\n",
       "      <td>0.570723</td>\n",
       "      <td>-2.592341</td>\n",
       "      <td>1.73230</td>\n",
       "      <td>-12.91800</td>\n",
       "      <td>9.207424</td>\n",
       "      <td>...</td>\n",
       "      <td>9.303061e-04</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.334449</td>\n",
       "      <td>0.625187</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.571870</td>\n",
       "      <td>9.188517e-04</td>\n",
       "      <td>0.030313</td>\n",
       "      <td>0.274486</td>\n",
       "      <td>jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>8.738784</td>\n",
       "      <td>34.0480</td>\n",
       "      <td>-6.7822</td>\n",
       "      <td>145.225186</td>\n",
       "      <td>12.050941</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>-2.417799</td>\n",
       "      <td>1.19030</td>\n",
       "      <td>-10.90200</td>\n",
       "      <td>9.233904</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968638e-04</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.396417</td>\n",
       "      <td>0.624749</td>\n",
       "      <td>0.693560</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>9.632708e-04</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.433661</td>\n",
       "      <td>jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>9.404261</td>\n",
       "      <td>34.8670</td>\n",
       "      <td>-5.3331</td>\n",
       "      <td>130.142955</td>\n",
       "      <td>11.408022</td>\n",
       "      <td>0.560963</td>\n",
       "      <td>-2.408945</td>\n",
       "      <td>0.81347</td>\n",
       "      <td>-8.21750</td>\n",
       "      <td>6.635468</td>\n",
       "      <td>...</td>\n",
       "      <td>9.194098e-04</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.524964</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>8.933477e-04</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.335023</td>\n",
       "      <td>jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>9.139112</td>\n",
       "      <td>32.5060</td>\n",
       "      <td>-6.8835</td>\n",
       "      <td>135.812815</td>\n",
       "      <td>11.653876</td>\n",
       "      <td>0.589304</td>\n",
       "      <td>-2.359531</td>\n",
       "      <td>1.32350</td>\n",
       "      <td>-9.57930</td>\n",
       "      <td>7.510565</td>\n",
       "      <td>...</td>\n",
       "      <td>5.788992e-04</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.624196</td>\n",
       "      <td>0.688560</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>1.025797e-03</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.272121</td>\n",
       "      <td>jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>8.868404</td>\n",
       "      <td>30.9070</td>\n",
       "      <td>-6.7151</td>\n",
       "      <td>128.743919</td>\n",
       "      <td>11.346538</td>\n",
       "      <td>0.585457</td>\n",
       "      <td>-2.144665</td>\n",
       "      <td>0.93113</td>\n",
       "      <td>-8.52640</td>\n",
       "      <td>6.022491</td>\n",
       "      <td>...</td>\n",
       "      <td>5.366838e-04</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.395776</td>\n",
       "      <td>0.633913</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>9.165240e-04</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.342332</td>\n",
       "      <td>jumping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5280 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "8635     9.298029     32.4980     -6.0782  134.634624   11.603216   \n",
       "8636     8.738784     34.0480     -6.7822  145.225186   12.050941   \n",
       "8637     9.404261     34.8670     -5.3331  130.142955   11.408022   \n",
       "8638     9.139112     32.5060     -6.8835  135.812815   11.653876   \n",
       "8639     8.868404     30.9070     -6.7151  128.743919   11.346538   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150     1.18320     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865     1.21290     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962     1.21280     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260     1.31700     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504     1.25740     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "8635     0.570723    -2.592341     1.73230   -12.91800    9.207424  ...   \n",
       "8636     0.760224    -2.417799     1.19030   -10.90200    9.233904  ...   \n",
       "8637     0.560963    -2.408945     0.81347    -8.21750    6.635468  ...   \n",
       "8638     0.589304    -2.359531     1.32350    -9.57930    7.510565  ...   \n",
       "8639     0.585457    -2.144665     0.93113    -8.52640    6.022491  ...   \n",
       "\n",
       "       LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
       "0     6.267229e-07     0.000792      0.177075     -0.057119    -0.054963   \n",
       "1     7.403458e-07     0.000860     -0.286918     -0.057268    -0.054945   \n",
       "2     5.802523e-07     0.000762     -0.134430     -0.057068    -0.054711   \n",
       "3     5.398837e-07     0.000735      0.021485     -0.056422    -0.053670   \n",
       "4     6.787533e-07     0.000824     -0.148229     -0.055801    -0.053313   \n",
       "...            ...          ...           ...           ...          ...   \n",
       "8635  9.303061e-04     0.030501      0.334449      0.625187     0.691300   \n",
       "8636  9.968638e-04     0.031573      0.396417      0.624749     0.693560   \n",
       "8637  9.194098e-04     0.030322      0.524964      0.631822     0.690120   \n",
       "8638  5.788992e-04     0.024060      0.301200      0.624196     0.688560   \n",
       "8639  5.366838e-04     0.023166      0.395776      0.633913     0.692860   \n",
       "\n",
       "      LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
       "0       -0.059241  6.778722e-07     0.000823      0.036729   sitting  \n",
       "1       -0.059589  7.032302e-07     0.000839      0.347471   sitting  \n",
       "2       -0.059065  6.268222e-07     0.000792      0.045579   sitting  \n",
       "3       -0.058310  8.011245e-07     0.000895      0.240690   sitting  \n",
       "4       -0.057815  6.853423e-07     0.000828      0.258429   sitting  \n",
       "...           ...           ...          ...           ...       ...  \n",
       "8635     0.571870  9.188517e-04     0.030313      0.274486   jumping  \n",
       "8636     0.570400  9.632708e-04     0.031037      0.433661   jumping  \n",
       "8637     0.581970  8.933477e-04     0.029889      0.335023   jumping  \n",
       "8638     0.573620  1.025797e-03     0.032028      0.272121   jumping  \n",
       "8639     0.586420  9.165240e-04     0.030274      0.342332   jumping  \n",
       "\n",
       "[5280 rows x 271 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cb362a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Define column name of the label vector\n",
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "features[LABEL] = le.fit_transform(features['activity'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "49f848d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(['activity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4b9dc4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     480\n",
       "4     480\n",
       "8     480\n",
       "1     480\n",
       "5     480\n",
       "9     480\n",
       "2     480\n",
       "6     480\n",
       "10    480\n",
       "3     480\n",
       "7     480\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "77c3dd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>ActivityEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.18320</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>6.267229e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.21290</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>7.403458e-07</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.21280</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.802523e-07</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.31700</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>5.398837e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.25740</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.787533e-07</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>9.298029</td>\n",
       "      <td>32.4980</td>\n",
       "      <td>-6.0782</td>\n",
       "      <td>134.634624</td>\n",
       "      <td>11.603216</td>\n",
       "      <td>0.570723</td>\n",
       "      <td>-2.592341</td>\n",
       "      <td>1.73230</td>\n",
       "      <td>-12.91800</td>\n",
       "      <td>9.207424</td>\n",
       "      <td>...</td>\n",
       "      <td>9.303061e-04</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.334449</td>\n",
       "      <td>0.625187</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.571870</td>\n",
       "      <td>9.188517e-04</td>\n",
       "      <td>0.030313</td>\n",
       "      <td>0.274486</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>8.738784</td>\n",
       "      <td>34.0480</td>\n",
       "      <td>-6.7822</td>\n",
       "      <td>145.225186</td>\n",
       "      <td>12.050941</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>-2.417799</td>\n",
       "      <td>1.19030</td>\n",
       "      <td>-10.90200</td>\n",
       "      <td>9.233904</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968638e-04</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.396417</td>\n",
       "      <td>0.624749</td>\n",
       "      <td>0.693560</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>9.632708e-04</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.433661</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>9.404261</td>\n",
       "      <td>34.8670</td>\n",
       "      <td>-5.3331</td>\n",
       "      <td>130.142955</td>\n",
       "      <td>11.408022</td>\n",
       "      <td>0.560963</td>\n",
       "      <td>-2.408945</td>\n",
       "      <td>0.81347</td>\n",
       "      <td>-8.21750</td>\n",
       "      <td>6.635468</td>\n",
       "      <td>...</td>\n",
       "      <td>9.194098e-04</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.524964</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>8.933477e-04</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.335023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>9.139112</td>\n",
       "      <td>32.5060</td>\n",
       "      <td>-6.8835</td>\n",
       "      <td>135.812815</td>\n",
       "      <td>11.653876</td>\n",
       "      <td>0.589304</td>\n",
       "      <td>-2.359531</td>\n",
       "      <td>1.32350</td>\n",
       "      <td>-9.57930</td>\n",
       "      <td>7.510565</td>\n",
       "      <td>...</td>\n",
       "      <td>5.788992e-04</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.624196</td>\n",
       "      <td>0.688560</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>1.025797e-03</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.272121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>8.868404</td>\n",
       "      <td>30.9070</td>\n",
       "      <td>-6.7151</td>\n",
       "      <td>128.743919</td>\n",
       "      <td>11.346538</td>\n",
       "      <td>0.585457</td>\n",
       "      <td>-2.144665</td>\n",
       "      <td>0.93113</td>\n",
       "      <td>-8.52640</td>\n",
       "      <td>6.022491</td>\n",
       "      <td>...</td>\n",
       "      <td>5.366838e-04</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.395776</td>\n",
       "      <td>0.633913</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>9.165240e-04</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.342332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5280 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "8635     9.298029     32.4980     -6.0782  134.634624   11.603216   \n",
       "8636     8.738784     34.0480     -6.7822  145.225186   12.050941   \n",
       "8637     9.404261     34.8670     -5.3331  130.142955   11.408022   \n",
       "8638     9.139112     32.5060     -6.8835  135.812815   11.653876   \n",
       "8639     8.868404     30.9070     -6.7151  128.743919   11.346538   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150     1.18320     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865     1.21290     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962     1.21280     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260     1.31700     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504     1.25740     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "8635     0.570723    -2.592341     1.73230   -12.91800    9.207424  ...   \n",
       "8636     0.760224    -2.417799     1.19030   -10.90200    9.233904  ...   \n",
       "8637     0.560963    -2.408945     0.81347    -8.21750    6.635468  ...   \n",
       "8638     0.589304    -2.359531     1.32350    -9.57930    7.510565  ...   \n",
       "8639     0.585457    -2.144665     0.93113    -8.52640    6.022491  ...   \n",
       "\n",
       "       LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
       "0     6.267229e-07     0.000792      0.177075     -0.057119    -0.054963   \n",
       "1     7.403458e-07     0.000860     -0.286918     -0.057268    -0.054945   \n",
       "2     5.802523e-07     0.000762     -0.134430     -0.057068    -0.054711   \n",
       "3     5.398837e-07     0.000735      0.021485     -0.056422    -0.053670   \n",
       "4     6.787533e-07     0.000824     -0.148229     -0.055801    -0.053313   \n",
       "...            ...          ...           ...           ...          ...   \n",
       "8635  9.303061e-04     0.030501      0.334449      0.625187     0.691300   \n",
       "8636  9.968638e-04     0.031573      0.396417      0.624749     0.693560   \n",
       "8637  9.194098e-04     0.030322      0.524964      0.631822     0.690120   \n",
       "8638  5.788992e-04     0.024060      0.301200      0.624196     0.688560   \n",
       "8639  5.366838e-04     0.023166      0.395776      0.633913     0.692860   \n",
       "\n",
       "      LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  ActivityEncoded  \n",
       "0       -0.059241  6.778722e-07     0.000823      0.036729                6  \n",
       "1       -0.059589  7.032302e-07     0.000839      0.347471                6  \n",
       "2       -0.059065  6.268222e-07     0.000792      0.045579                6  \n",
       "3       -0.058310  8.011245e-07     0.000895      0.240690                6  \n",
       "4       -0.057815  6.853423e-07     0.000828      0.258429                6  \n",
       "...           ...           ...          ...           ...              ...  \n",
       "8635     0.571870  9.188517e-04     0.030313      0.274486                2  \n",
       "8636     0.570400  9.632708e-04     0.031037      0.433661                2  \n",
       "8637     0.581970  8.933477e-04     0.029889      0.335023                2  \n",
       "8638     0.573620  1.025797e-03     0.032028      0.272121                2  \n",
       "8639     0.586420  9.165240e-04     0.030274      0.342332                2  \n",
       "\n",
       "[5280 rows x 271 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2b041c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsitting                    6\\nstanding                   7\\nlyingBack                  3\\nlyingRigh                  4\\n\\nascendingStairs            0\\ndecendingStairs            1\\nwalkingLot                 8\\nwalkingTreadmillFlat       9\\nwalkingTreadmillIncline    10\\n\\nrunningTreadmill           5\\njumping                    2\\n'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sitting                    6\n",
    "standing                   7\n",
    "lyingBack                  3\n",
    "lyingRigh                  4\n",
    "\n",
    "ascendingStairs            0\n",
    "decendingStairs            1\n",
    "walkingLot                 8\n",
    "walkingTreadmillFlat       9\n",
    "walkingTreadmillIncline    10\n",
    "\n",
    "runningTreadmill           5\n",
    "jumping                    2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "21f337af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     480\n",
       "4     480\n",
       "8     480\n",
       "1     480\n",
       "5     480\n",
       "9     480\n",
       "2     480\n",
       "6     480\n",
       "10    480\n",
       "3     480\n",
       "7     480\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f1788d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST CODE 1\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.boxplot(x='ActivityEncoded', y='T_xacc_std',data=features, showfliers=False, saturation=1)\n",
    "plt.ylabel('Standard Deviation for Acceleration X')\n",
    "\n",
    "plt.axhline(y=5.5,dashes=(5,5), c='g')\n",
    "plt.axhline(y=1, dashes=(5,5), c='m')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "dcb09c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     480\n",
       "4     480\n",
       "8     480\n",
       "1     480\n",
       "5     480\n",
       "9     480\n",
       "2     480\n",
       "6     480\n",
       "10    480\n",
       "3     480\n",
       "7     480\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "33855f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Start\n",
      "End\n",
      "Time: 0.0min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Trainig Start\")\n",
    "\n",
    "condition = np.where(features['T_xacc_std'] > 0.4)\n",
    "features2 = features.iloc[condition]\n",
    "\n",
    "condition = np.where(features2['T_xacc_std'] < 5.5)\n",
    "new_features = features2.iloc[condition]\n",
    "\n",
    "print(\"End\")\n",
    "print(\"Time: {:.1f}min\".format(((time.time() - start_time))/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "73d629e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     480\n",
       "8     480\n",
       "10    480\n",
       "1     480\n",
       "9     480\n",
       "3       3\n",
       "2       2\n",
       "4       1\n",
       "6       1\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "32732416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "idx = new_features[new_features['ActivityEncoded'] == 3].index\n",
    "new_features.drop(idx , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2125bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "idx = new_features[new_features['ActivityEncoded'] == 2].index\n",
    "new_features.drop(idx , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "92f1e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "idx = new_features[new_features['ActivityEncoded'] == 4].index\n",
    "new_features.drop(idx , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a414331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "idx = new_features[new_features['ActivityEncoded'] == 6].index\n",
    "new_features.drop(idx , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b450e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     480\n",
       "8     480\n",
       "10    480\n",
       "1     480\n",
       "9     480\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "41536586",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = new_features.replace({'ActivityEncoded':8},2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8de05a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = new_features.replace({'ActivityEncoded':10},3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "77b250da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = new_features.replace({'ActivityEncoded':9},4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f5b3fadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    480\n",
       "2    480\n",
       "4    480\n",
       "1    480\n",
       "3    480\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b95b7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.concat([new_features, new_features], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fb80f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    960\n",
       "4    960\n",
       "1    960\n",
       "2    960\n",
       "3    960\n",
       "Name: ActivityEncoded, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features['ActivityEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ace783c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from matplotlib import pyplot\n",
    "from keras import backend\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4979f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
      "1920     7.570732      15.061         0.0   17.169455    4.143604   \n",
      "1921     7.544015      15.433         0.0   16.827956    4.102189   \n",
      "1922     7.571806      16.878         0.0   18.861743    4.343011   \n",
      "1923     7.463242      14.912         0.0   16.403361    4.050106   \n",
      "1924     7.624589      14.823         0.0   17.000649    4.123184   \n",
      "\n",
      "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
      "1920    -0.864170     0.044689      1.6809     -1.7616    0.856312  ...   \n",
      "1921    -0.867638     0.192589      2.0541     -1.3427    1.219419  ...   \n",
      "1922    -0.513859     0.471196      2.8308     -1.9441    1.042799  ...   \n",
      "1923    -0.907132     0.442211      2.2893     -1.6441    0.810045  ...   \n",
      "1924    -0.935006     0.325602      2.2835     -2.8210    1.215301  ...   \n",
      "\n",
      "      T_ymag_min  T_ymag_var  T_ymag_std  T_ymag_skew  T_zmag_mean  \\\n",
      "1920         0.0    0.044656    0.211320    -1.347671    -0.344403   \n",
      "1921         0.0    0.034243    0.185050    -1.340975    -0.353760   \n",
      "1922         0.0    0.021825    0.147731    -1.434691    -0.348211   \n",
      "1923         0.0    0.018573    0.136283    -1.257747    -0.386458   \n",
      "1924         0.0    0.020241    0.142270    -1.318642    -0.359054   \n",
      "\n",
      "      T_zmag_max  T_zmag_min  T_zmag_var  T_zmag_std  T_zmag_skew  \n",
      "1920         0.0    -0.53711    0.033384    0.182712     1.114581  \n",
      "1921         0.0    -0.50133    0.032372    0.179923     1.404258  \n",
      "1922         0.0    -0.49264    0.031062    0.176245     1.437678  \n",
      "1923         0.0    -0.57011    0.039590    0.198972     1.315785  \n",
      "1924         0.0    -0.52367    0.033563    0.183202     1.380210  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_col_all = ['T_xacc_mean', 'T_xacc_max', 'T_xacc_min','T_xacc_var',\n",
    "       'T_xacc_std', 'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min',\n",
    "       'T_yacc_var', 'T_yacc_std', 'T_yacc_skew', 'T_zacc_mean', 'T_zacc_max',\n",
    "       'T_zacc_min', 'T_zacc_var', 'T_zacc_std', 'T_zacc_skew', 'T_xgyro_mean',\n",
    "       'T_xgyro_max', 'T_xgyro_min', 'T_xgyro_var', 'T_xgyro_std',\n",
    "       'T_xgyro_skew', 'T_ygyro_mean', 'T_ygyro_max', 'T_ygyro_min',\n",
    "       'T_ygyro_var', 'T_ygyro_std', 'T_ygyro_skew', 'T_zgyro_mean',\n",
    "       'T_zgyro_max', 'T_zgyro_min', 'T_zgyro_var', 'T_zgyro_std',\n",
    "       'T_zgyro_skew', 'T_xmag_mean', 'T_xmag_max', 'T_xmag_min', 'T_xmag_var',\n",
    "       'T_xmag_std', 'T_xmag_skew', 'T_ymag_mean', 'T_ymag_max', 'T_ymag_min',\n",
    "       'T_ymag_var', 'T_ymag_std', 'T_ymag_skew', 'T_zmag_mean', 'T_zmag_max',\n",
    "       'T_zmag_min', 'T_zmag_var', 'T_zmag_std', 'T_zmag_skew']\n",
    "       \n",
    "\n",
    "X = new_features[f_col_all]  # all features\n",
    "\n",
    "X_OneHotEncoded = pd.get_dummies(X)  # all features and OneHotEncoded\n",
    "f_col_OHE = list(X_OneHotEncoded.columns.values)\n",
    "\n",
    "y = new_features[\"ActivityEncoded\"].apply(lambda x: 1 if x== \"Yes\" else 0 )  # Labels\n",
    "y = new_features[\"ActivityEncoded\"]\n",
    "print(X_OneHotEncoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f6946ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a68a326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (4752, 54)\n",
      "y_train : (4752,)\n",
      "X_test : (48, 54)\n",
      "y_test : (48,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_OneHotEncoded, y, test_size=0.01, random_state=6)\n",
    "\n",
    "print(\"X_train :\", X_train.shape)\n",
    "print(\"y_train :\", y_train.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "print(\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f3e7074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from matplotlib import pyplot\n",
    "from keras import backend\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8ac0bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 5\n",
    "INPUT_SIZE = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3160c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom activation function\n",
    "def custom_activation(output):\n",
    "\tlogexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
    "\tresult = logexpsum / (logexpsum + 1.0)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c56f7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_classes=CLASSES):\n",
    "  # image input\n",
    "  in_image = Input(shape=(INPUT_SIZE,))   \n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(in_image)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)\n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(fe)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)\n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(fe)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)\n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(fe)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)\n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(fe)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)\n",
    "  # downsample\n",
    "  fe = Dense(units=128, activation='relu')(fe)\n",
    "  fe = LeakyReLU(alpha=0.2)(fe)    \n",
    "  # dropout\n",
    "  fe = Dropout(0.4)(fe)\n",
    "  # output layer nodes\n",
    "  fe = Dense(n_classes)(fe)\n",
    "  # supervised output\n",
    "  c_out_layer = Activation('softmax')(fe)\n",
    "\n",
    "  # define and compile supervised discriminator model\n",
    "  \n",
    "  c_model = Model(in_image, c_out_layer)\n",
    "  c_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.003, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "  # unsupervised output\n",
    "  d_out_layer = Lambda(custom_activation)(fe)\n",
    "\n",
    "  # define and compile unsupervised discriminator model\n",
    "  d_model = Model(in_image, d_out_layer)\n",
    "  d_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.003, beta_1=0.5))    \n",
    "  d_model.summary()\n",
    "  return d_model, c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e7f11574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_outputs=INPUT_SIZE):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(200, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(128, activation='relu'))    \n",
    "\tmodel.add(Dense(128, activation='relu'))     \n",
    "\tmodel.add(Dense(128, activation='relu'))       \n",
    "\tmodel.add(Dense(n_outputs, activation='relu'))\n",
    "\tmodel.summary()\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "54e5c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# connect image output from generator as input to discriminator\n",
    "\tgan_output = d_model(g_model.output)\n",
    "\t# define gan model as taking noise and outputting a classification\n",
    "\tmodel = Model(g_model.input, gan_output)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.003, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "db9be0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images\n",
    "def load_real_samples(X,y):    \n",
    "\tX = X / 20\n",
    "\tprint(X.shape, y.shape)\n",
    "\treturn [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "741f6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a supervised subset of the dataset, ensures classes are balanced\n",
    "def select_supervised_samples(dataset2, n_samples=143, n_classes=CLASSES):\n",
    "  X, y = dataset2\n",
    "  rand = randint(0,1000)\n",
    "  #n_per_class = int(n_samples / n_classes)\n",
    "  n_per_class = int(n_samples)\n",
    "  return X.sample(n=n_per_class,replace=False, random_state=rand), y.sample(n=n_per_class,replace=False, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "efbdffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# split into images and labels\n",
    "  features, labels = dataset\n",
    "\t# choose random instances\n",
    "  rand = randint(0, 1000)\n",
    "\t# select features and labels\n",
    "  X = features.sample(n=n_samples,random_state=rand)\n",
    "  labels = labels.sample(n=n_samples,random_state=rand)\n",
    "\t# generate class labels\n",
    "  y = ones((n_samples, 1))\n",
    "  return [X, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tz_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = z_input.reshape(n_samples, latent_dim)\n",
    "\treturn z_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tz_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\timages = generator.predict(z_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn images, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "397e6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "\n",
    "def summarize_performance(step, g_model, c_model, latent_dim, dataset, acc_list, n_samples=100):\n",
    "    \n",
    "\t# evaluate the classifier model\n",
    "\tX, y = dataset\n",
    "\t_, acc = c_model.evaluate(X, y, verbose=0)\n",
    "\tprint('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
    "\tacc_list.append(acc)\n",
    "\n",
    "    \n",
    "\t# save the generator model\n",
    "\tfilename2 = 'models/g_model_%04d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "    \n",
    "\t# save the classifier model\n",
    "\tfilename3 = 'models/c_model_%04d.h5' % (step+1)\n",
    "\tc_model.save(filename3)\n",
    "\t#print('>Saved:  %s and %s' % (filename2, filename3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "aa608943",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_supervised_losses=[]\n",
    "g_supervised_losses=[]\n",
    "c_accuray=[]\n",
    "iteration_checkpoints=[]\n",
    "\n",
    "\n",
    "def train(g_model, d_model, c_model, gan_model, dataset, latent_dim, acc_list, n_epochs=200, n_batch=100):\n",
    "    \n",
    "\t# select supervised dataset\n",
    "\tX_sup, y_sup = select_supervised_samples(dataset)\n",
    "\tprint(\"Select supervised dataset: \", X_sup.shape, y_sup.shape)\n",
    "    \n",
    "\t#print(\"Select extended supervised dataset: \", X_sup2.shape, y_sup2.shape)\n",
    "    \n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    \n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "\t# calculate the size of half a batch of samples\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\tprint('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
    "    \n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# update supervised discriminator (c)\n",
    "\t\t[Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
    "\t\tc_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
    "\t\t# update unsupervised discriminator (d)\n",
    "\t\t[X_real, _], y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\td_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\td_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# update generator (g)\n",
    "\t\tX_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, c[%.3f,%.0f%%], d[%.3f,%.3f], g[%.3f]' % (i+1, c_loss, c_acc*100, d_loss1, d_loss2, g_loss))                \n",
    "\n",
    "        # evaluate the model performance every so often           \n",
    "\t\tif (i+1) % (100) == 0:            \n",
    "\t\t\tsummarize_performance(i, g_model, c_model, latent_dim, dataset, acc_list)\n",
    "\t\t\td_supervised_losses.append(d_loss1)\n",
    "\t\t\tg_supervised_losses.append(g_loss)\n",
    "\t\t\tc_accuray.append(c_acc)\n",
    "\t\t\titeration_checkpoints.append(i+1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2b4bec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 54)]              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               7040      \n",
      "                                                                 \n",
      " leaky_re_lu_36 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_37 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_38 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_40 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " leaky_re_lu_41 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      " lambda_6 (Lambda)           (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,245\n",
      "Trainable params: 90,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 128)               25728     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 54)                6966      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,430\n",
      "Trainable params: 102,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4752, 54) (4752,)\n",
      "Total dataset:  (4752, 54) (4752,)\n"
     ]
    }
   ],
   "source": [
    "#accuracy list for each epochs\n",
    "acc_list = []\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator models\n",
    "d_model, c_model = define_discriminator()\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples(X_train,y_train)\n",
    "\n",
    "X, y = dataset\n",
    "dataset2 = dataset.copy()\n",
    "\n",
    "print(\"Total dataset: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6656faf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Start\n",
      "Select supervised dataset:  (143, 54) (143,)\n",
      "n_epochs=200, n_batch=100, 1/2=50, b/e=47, steps=9400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">1, c[1.611,18%], d[0.181,1.833], g[0.180]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">2, c[1.607,22%], d[0.178,1.807], g[0.186]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">3, c[1.607,20%], d[0.179,1.773], g[0.192]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">4, c[1.599,26%], d[0.182,1.751], g[0.198]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">5, c[1.599,22%], d[0.180,1.728], g[0.205]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">6, c[1.595,26%], d[0.179,1.709], g[0.209]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">7, c[1.597,22%], d[0.174,1.699], g[0.212]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">8, c[1.583,22%], d[0.167,1.675], g[0.220]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">9, c[1.579,22%], d[0.161,1.630], g[0.237]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">10, c[1.614,24%], d[0.152,1.548], g[0.262]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">11, c[1.594,26%], d[0.152,1.438], g[0.312]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">12, c[1.588,32%], d[0.127,1.262], g[0.447]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">13, c[1.652,24%], d[0.132,0.968], g[0.686]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">14, c[1.488,30%], d[0.118,0.882], g[1.268]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">15, c[1.453,36%], d[0.216,0.509], g[1.586]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">16, c[1.715,20%], d[0.076,0.567], g[2.592]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">17, c[1.625,24%], d[0.207,0.263], g[2.412]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">18, c[1.450,56%], d[0.056,1.294], g[3.327]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">19, c[1.629,28%], d[0.169,0.385], g[3.484]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">20, c[1.960,14%], d[0.207,0.446], g[3.166]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">21, c[1.600,20%], d[0.159,0.838], g[3.560]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">22, c[1.687,18%], d[0.298,0.294], g[3.102]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">23, c[1.495,30%], d[0.305,0.491], g[3.347]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">24, c[1.346,46%], d[0.573,0.243], g[2.538]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">25, c[1.394,40%], d[0.442,0.670], g[4.141]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">26, c[1.318,48%], d[0.723,0.297], g[3.413]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">27, c[1.410,48%], d[0.330,0.978], g[5.183]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">28, c[1.556,36%], d[0.467,0.048], g[3.682]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">29, c[1.388,32%], d[0.197,0.225], g[2.600]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">30, c[1.355,44%], d[0.254,0.142], g[2.861]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">31, c[1.321,40%], d[0.505,0.108], g[2.781]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">32, c[1.362,38%], d[0.423,0.110], g[2.627]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">33, c[1.369,38%], d[0.529,0.215], g[2.720]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">34, c[1.276,46%], d[0.585,0.391], g[4.035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">35, c[1.207,46%], d[0.580,0.082], g[3.373]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">36, c[1.186,56%], d[0.323,0.169], g[3.238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">37, c[1.253,58%], d[0.362,0.044], g[3.760]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">38, c[1.186,60%], d[0.395,0.062], g[3.491]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">39, c[1.256,48%], d[0.319,0.093], g[3.172]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">40, c[1.154,56%], d[0.341,0.060], g[2.980]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">41, c[1.314,46%], d[0.162,0.197], g[2.736]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">42, c[1.246,50%], d[0.182,0.123], g[3.116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">43, c[1.127,56%], d[0.267,0.046], g[3.299]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">44, c[1.102,58%], d[0.243,0.081], g[3.239]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">45, c[1.132,48%], d[0.108,0.073], g[3.190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">46, c[1.165,50%], d[0.091,0.072], g[3.157]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">47, c[1.169,48%], d[0.172,0.058], g[3.491]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">48, c[1.009,58%], d[0.210,0.063], g[3.250]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">49, c[0.911,58%], d[0.142,0.110], g[2.921]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">50, c[0.947,62%], d[0.147,0.151], g[3.202]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">51, c[0.908,64%], d[0.049,0.111], g[3.832]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">52, c[0.833,64%], d[0.070,0.098], g[4.003]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">53, c[1.119,62%], d[0.118,0.556], g[5.264]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">54, c[1.022,62%], d[0.182,0.076], g[5.066]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">55, c[0.878,72%], d[0.066,0.784], g[7.079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">56, c[1.303,42%], d[0.047,0.051], g[5.940]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">57, c[0.932,64%], d[0.117,0.336], g[8.234]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">58, c[0.979,68%], d[0.419,0.008], g[6.162]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">59, c[1.159,48%], d[0.491,0.024], g[3.198]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">60, c[1.079,52%], d[0.284,0.082], g[3.432]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">61, c[1.083,52%], d[0.214,0.098], g[5.900]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">62, c[0.960,58%], d[0.157,0.083], g[5.451]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">63, c[0.923,56%], d[0.118,0.083], g[5.777]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">64, c[0.778,72%], d[0.055,0.008], g[6.246]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">65, c[0.934,56%], d[0.156,0.020], g[5.396]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">66, c[0.695,72%], d[0.065,0.013], g[5.764]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">67, c[0.748,60%], d[0.104,0.141], g[9.002]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">68, c[0.847,60%], d[0.089,0.001], g[7.938]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">69, c[0.744,72%], d[0.144,0.003], g[5.966]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">70, c[0.864,66%], d[0.147,0.005], g[5.170]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">71, c[0.925,58%], d[0.225,0.030], g[3.767]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">72, c[0.707,74%], d[0.042,0.040], g[4.092]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">73, c[0.835,58%], d[0.007,0.133], g[5.320]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">74, c[0.662,72%], d[0.015,0.006], g[7.027]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">75, c[0.657,82%], d[0.115,0.005], g[6.062]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">76, c[0.486,84%], d[0.135,0.018], g[4.692]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">77, c[0.771,66%], d[0.030,0.054], g[6.149]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">78, c[0.601,78%], d[0.015,0.020], g[5.801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">79, c[0.657,76%], d[0.054,0.009], g[6.195]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">80, c[0.527,82%], d[0.013,0.042], g[6.791]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">81, c[0.540,70%], d[0.077,0.003], g[6.364]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">82, c[0.581,82%], d[0.019,0.005], g[6.157]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">83, c[0.544,82%], d[0.026,0.007], g[6.021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">84, c[0.388,88%], d[0.045,0.044], g[5.696]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">85, c[0.352,92%], d[0.029,0.336], g[10.930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">86, c[1.737,40%], d[0.008,0.001], g[8.695]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">87, c[1.198,54%], d[0.138,0.007], g[7.068]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">88, c[0.658,76%], d[0.296,0.018], g[4.649]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">89, c[0.793,68%], d[0.080,0.263], g[7.966]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">90, c[1.135,66%], d[0.049,0.003], g[7.252]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">91, c[0.658,78%], d[0.027,0.004], g[6.565]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">92, c[0.713,74%], d[0.057,0.005], g[6.447]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">93, c[0.581,80%], d[0.056,0.003], g[6.695]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">94, c[0.507,80%], d[0.100,0.004], g[6.029]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">95, c[0.670,76%], d[0.024,0.008], g[6.047]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">96, c[0.461,92%], d[0.011,0.011], g[5.400]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">97, c[0.656,78%], d[0.017,0.251], g[10.011]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">98, c[0.860,70%], d[0.029,0.000], g[9.984]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">99, c[0.681,70%], d[0.062,0.001], g[8.010]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">100, c[0.725,64%], d[0.063,0.002], g[7.209]\n",
      "Classifier Accuracy: 73.569%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">101, c[0.501,76%], d[0.266,0.008], g[4.951]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">102, c[1.004,68%], d[0.050,0.011], g[5.729]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">103, c[0.539,76%], d[0.035,0.009], g[6.260]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">104, c[0.377,90%], d[0.030,0.042], g[7.966]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">105, c[0.385,90%], d[0.042,0.003], g[7.844]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">106, c[0.578,84%], d[0.027,0.002], g[7.209]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">107, c[0.344,88%], d[0.034,0.006], g[6.943]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">108, c[0.462,82%], d[0.007,0.008], g[7.097]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">109, c[0.453,80%], d[0.007,0.036], g[6.828]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">110, c[0.438,82%], d[0.004,0.006], g[7.626]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">111, c[0.235,92%], d[0.009,0.002], g[7.972]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">112, c[0.374,88%], d[0.023,0.001], g[8.021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">113, c[0.423,88%], d[0.067,0.006], g[6.457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">114, c[0.259,92%], d[0.010,0.013], g[6.705]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">115, c[0.237,96%], d[0.005,0.010], g[7.436]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">116, c[0.232,96%], d[0.014,0.003], g[7.823]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">117, c[0.357,86%], d[0.010,0.001], g[8.093]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">118, c[0.411,84%], d[0.031,0.007], g[8.265]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">119, c[0.246,92%], d[0.009,0.046], g[14.381]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">120, c[0.338,82%], d[0.034,0.000], g[14.104]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">121, c[0.545,84%], d[0.034,0.000], g[12.306]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">122, c[0.366,84%], d[0.006,0.000], g[10.978]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">123, c[0.343,78%], d[0.028,0.001], g[8.977]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">124, c[0.194,96%], d[0.005,0.001], g[8.602]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">125, c[0.306,88%], d[0.002,0.001], g[8.319]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">126, c[0.323,86%], d[0.003,0.001], g[8.148]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">127, c[0.209,92%], d[0.006,0.002], g[8.712]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">128, c[0.250,90%], d[0.007,0.002], g[8.636]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">129, c[0.477,86%], d[0.004,0.001], g[8.440]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">130, c[0.233,94%], d[0.002,0.001], g[8.500]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">131, c[0.207,94%], d[0.002,0.002], g[8.088]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">132, c[0.214,92%], d[0.014,0.002], g[8.299]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">133, c[0.102,100%], d[0.005,0.006], g[8.655]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">134, c[0.360,88%], d[0.009,0.001], g[8.333]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">135, c[0.244,92%], d[0.004,0.005], g[7.785]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">136, c[0.128,94%], d[0.004,0.001], g[7.987]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">137, c[0.181,90%], d[0.003,0.001], g[8.248]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">138, c[0.204,94%], d[0.009,0.001], g[7.657]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">139, c[0.242,94%], d[0.009,0.004], g[7.518]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">140, c[0.113,98%], d[0.010,0.006], g[7.560]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">141, c[0.180,94%], d[0.001,0.011], g[7.832]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">142, c[0.134,98%], d[0.002,0.092], g[13.974]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">143, c[0.381,86%], d[0.001,0.001], g[12.610]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">144, c[0.276,86%], d[0.140,0.002], g[12.208]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">145, c[0.379,84%], d[0.167,0.086], g[12.605]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">146, c[0.615,72%], d[0.121,0.000], g[11.522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">147, c[0.453,84%], d[0.014,0.003], g[9.905]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">148, c[0.681,76%], d[0.002,0.025], g[9.070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">149, c[0.278,88%], d[0.000,0.001], g[9.035]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">150, c[0.330,86%], d[0.008,0.000], g[9.583]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">151, c[0.273,90%], d[0.003,0.001], g[9.519]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">152, c[0.146,94%], d[0.001,0.000], g[9.153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">153, c[0.200,96%], d[0.001,0.001], g[10.080]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">154, c[0.249,90%], d[0.001,0.001], g[9.723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">155, c[0.170,94%], d[0.001,0.000], g[9.115]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">156, c[0.258,94%], d[0.002,0.000], g[9.520]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">157, c[0.269,92%], d[0.006,0.001], g[9.869]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">158, c[0.147,94%], d[0.001,0.001], g[9.775]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">159, c[0.309,92%], d[0.001,0.001], g[9.376]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">160, c[0.276,92%], d[0.005,0.001], g[9.648]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">161, c[0.162,92%], d[0.001,0.002], g[9.226]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">162, c[0.190,96%], d[0.001,0.000], g[9.002]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">163, c[0.132,94%], d[0.002,0.001], g[9.333]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">164, c[0.158,96%], d[0.001,0.000], g[9.200]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">165, c[0.095,98%], d[0.004,0.002], g[9.647]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">166, c[0.122,94%], d[0.001,0.005], g[9.263]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">167, c[0.071,98%], d[0.001,0.002], g[8.557]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">168, c[0.337,84%], d[0.002,0.022], g[9.830]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">169, c[0.089,98%], d[0.018,0.005], g[10.915]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">170, c[0.341,90%], d[0.001,0.014], g[12.426]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">171, c[0.179,94%], d[0.001,0.001], g[11.208]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">172, c[0.146,94%], d[0.010,0.004], g[10.398]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">173, c[0.079,98%], d[0.004,0.295], g[15.125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">174, c[3.261,34%], d[0.033,0.000], g[15.370]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">175, c[1.327,56%], d[0.017,0.000], g[15.280]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">176, c[1.364,62%], d[0.123,0.000], g[15.027]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">177, c[1.072,64%], d[0.206,0.000], g[13.234]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">178, c[0.816,66%], d[0.102,0.000], g[10.370]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">179, c[0.327,92%], d[0.021,0.000], g[9.434]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">180, c[0.572,72%], d[0.004,0.001], g[8.471]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">181, c[0.452,82%], d[0.004,0.002], g[8.562]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">182, c[0.305,86%], d[0.002,0.002], g[8.356]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">183, c[0.247,98%], d[0.001,0.004], g[7.772]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">184, c[0.261,94%], d[0.005,0.003], g[8.507]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">185, c[0.276,96%], d[0.004,0.002], g[8.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">186, c[0.224,94%], d[0.002,0.002], g[8.363]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">187, c[0.286,92%], d[0.008,0.004], g[8.825]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">188, c[0.307,92%], d[0.001,0.021], g[8.381]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">189, c[0.196,94%], d[0.001,0.001], g[9.043]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">190, c[0.225,90%], d[0.001,0.010], g[9.848]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">191, c[0.240,90%], d[0.001,0.004], g[9.462]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">192, c[0.388,88%], d[0.001,0.006], g[9.958]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">193, c[0.138,100%], d[0.002,0.001], g[10.845]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">194, c[0.295,90%], d[0.002,0.000], g[11.627]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">195, c[0.208,94%], d[0.002,0.000], g[10.920]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">196, c[0.144,96%], d[0.090,0.000], g[9.627]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">197, c[0.203,96%], d[0.004,0.001], g[9.411]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">198, c[0.231,92%], d[0.002,0.001], g[9.667]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">199, c[0.075,98%], d[0.002,0.002], g[10.457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">200, c[0.209,92%], d[0.001,0.002], g[10.053]\n",
      "Classifier Accuracy: 90.699%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">201, c[0.173,96%], d[0.002,0.001], g[9.944]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">202, c[0.085,98%], d[0.001,0.001], g[10.775]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">203, c[0.179,96%], d[0.001,0.001], g[11.295]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">204, c[0.108,96%], d[0.001,0.001], g[11.906]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">205, c[0.155,98%], d[0.002,0.001], g[11.971]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">206, c[0.118,96%], d[0.004,0.001], g[12.028]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">207, c[0.110,98%], d[0.002,0.006], g[12.237]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">208, c[0.101,96%], d[0.002,0.003], g[11.500]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">209, c[0.188,96%], d[0.001,0.000], g[12.232]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">210, c[0.122,94%], d[0.001,0.001], g[11.387]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">211, c[0.166,96%], d[0.002,0.000], g[10.862]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">212, c[0.189,94%], d[0.001,0.001], g[10.752]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">213, c[0.086,98%], d[0.005,0.001], g[11.313]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">214, c[0.117,94%], d[0.000,0.001], g[10.646]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">215, c[0.125,96%], d[0.000,0.000], g[10.681]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">216, c[0.248,92%], d[0.004,0.002], g[10.749]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">217, c[0.068,98%], d[0.004,0.000], g[11.364]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">218, c[0.077,98%], d[0.000,0.001], g[11.342]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">219, c[0.078,98%], d[0.001,0.000], g[11.226]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">220, c[0.074,100%], d[0.002,0.000], g[10.989]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">221, c[0.086,96%], d[0.001,0.001], g[11.144]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">222, c[0.194,94%], d[0.000,0.001], g[11.150]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">223, c[0.161,94%], d[0.002,0.000], g[11.693]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">224, c[0.062,98%], d[0.000,0.001], g[11.371]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">225, c[0.039,100%], d[0.002,0.001], g[11.985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">226, c[0.122,96%], d[0.002,0.000], g[11.319]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">227, c[0.045,100%], d[0.000,0.000], g[11.529]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">228, c[0.133,96%], d[0.001,0.001], g[11.564]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">229, c[0.135,98%], d[0.001,0.000], g[10.788]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">230, c[0.045,100%], d[0.000,0.001], g[11.084]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">231, c[0.138,94%], d[0.002,0.000], g[11.114]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">232, c[0.038,100%], d[0.000,0.000], g[11.057]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">233, c[0.162,96%], d[0.000,0.001], g[10.842]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">234, c[0.069,98%], d[0.000,0.007], g[10.828]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">235, c[0.134,96%], d[0.002,0.000], g[11.833]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">236, c[0.066,100%], d[0.000,0.001], g[12.044]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">237, c[0.037,100%], d[0.009,0.000], g[10.491]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">238, c[0.128,96%], d[0.001,0.000], g[10.933]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">239, c[0.051,100%], d[0.000,0.000], g[11.204]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">240, c[0.110,98%], d[0.000,0.000], g[11.216]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">241, c[0.026,100%], d[0.000,0.000], g[11.414]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">242, c[0.022,100%], d[0.000,0.000], g[11.275]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">243, c[0.030,100%], d[0.000,0.000], g[11.522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">244, c[0.064,98%], d[0.000,0.000], g[11.912]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">245, c[0.015,100%], d[0.000,0.000], g[12.206]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">246, c[0.039,98%], d[0.000,0.000], g[12.250]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">247, c[0.048,98%], d[0.000,0.000], g[12.466]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">248, c[0.052,98%], d[0.000,0.000], g[12.194]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">249, c[0.049,98%], d[0.000,0.000], g[12.022]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">250, c[0.063,98%], d[0.000,0.000], g[12.190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">251, c[0.037,100%], d[0.000,0.000], g[12.395]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">252, c[0.055,98%], d[0.001,0.000], g[12.260]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">253, c[0.050,100%], d[0.000,0.000], g[11.942]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">254, c[0.071,98%], d[0.001,0.000], g[12.027]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">255, c[0.088,98%], d[0.000,0.000], g[12.142]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">256, c[0.024,100%], d[0.000,0.000], g[12.374]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">257, c[0.024,100%], d[0.000,0.000], g[12.585]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">258, c[0.075,98%], d[0.000,0.000], g[12.065]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">259, c[0.070,98%], d[0.000,0.000], g[12.266]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">260, c[0.111,96%], d[0.000,0.000], g[12.172]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">261, c[0.108,94%], d[0.001,0.000], g[11.553]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">262, c[0.050,98%], d[0.000,0.000], g[11.521]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">263, c[0.082,98%], d[0.000,0.000], g[12.472]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">264, c[0.150,94%], d[0.000,0.000], g[12.327]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">265, c[0.064,98%], d[0.000,0.000], g[13.089]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">266, c[0.095,96%], d[0.000,0.000], g[12.167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">267, c[0.043,98%], d[0.000,0.000], g[11.953]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">268, c[0.024,100%], d[0.000,0.000], g[11.961]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">269, c[0.012,100%], d[0.001,0.000], g[12.366]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">270, c[0.019,100%], d[0.000,0.000], g[12.317]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">271, c[0.071,98%], d[0.000,0.000], g[12.940]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">272, c[0.043,98%], d[0.008,0.000], g[11.895]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">273, c[0.117,96%], d[0.000,0.000], g[11.369]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">274, c[0.073,96%], d[0.000,0.000], g[11.817]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">275, c[0.039,100%], d[0.000,0.000], g[12.141]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">276, c[0.018,100%], d[0.000,0.000], g[12.440]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">277, c[0.036,100%], d[0.000,0.001], g[12.072]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">278, c[0.034,98%], d[0.000,0.000], g[11.958]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">279, c[0.055,96%], d[0.003,0.000], g[11.566]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">280, c[0.035,100%], d[0.000,0.001], g[11.670]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      ">281, c[0.010,100%], d[0.000,0.000], g[12.616]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">282, c[0.030,98%], d[0.000,0.001], g[12.163]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">283, c[0.015,100%], d[0.000,0.000], g[12.322]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">284, c[0.066,96%], d[0.000,0.000], g[12.456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">285, c[0.022,100%], d[0.000,0.000], g[12.589]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">286, c[0.028,100%], d[0.000,0.000], g[12.833]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">287, c[0.116,98%], d[0.000,0.000], g[12.246]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">288, c[0.017,100%], d[0.000,0.000], g[12.187]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">289, c[0.020,100%], d[0.000,0.000], g[12.098]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">290, c[0.053,98%], d[0.000,0.000], g[12.522]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">291, c[0.023,100%], d[0.000,0.000], g[12.881]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">292, c[0.028,100%], d[0.000,0.000], g[12.365]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">293, c[0.036,100%], d[0.001,0.000], g[12.370]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">294, c[0.023,100%], d[0.000,0.000], g[12.575]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">295, c[0.056,98%], d[0.001,0.000], g[12.588]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">296, c[0.049,98%], d[0.000,0.000], g[12.087]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">297, c[0.063,98%], d[0.000,0.000], g[11.972]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">298, c[0.041,98%], d[0.000,0.000], g[11.235]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">299, c[0.037,98%], d[0.000,0.010], g[12.680]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">300, c[0.021,100%], d[0.000,0.000], g[12.852]\n",
      "Classifier Accuracy: 93.960%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">301, c[0.020,100%], d[0.001,0.000], g[12.865]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">302, c[0.011,100%], d[0.000,0.000], g[12.577]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">303, c[0.011,100%], d[0.000,0.002], g[12.881]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">304, c[0.024,100%], d[0.000,0.001], g[13.269]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">305, c[0.007,100%], d[0.000,0.000], g[13.169]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">306, c[0.012,100%], d[0.000,0.000], g[12.969]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">307, c[0.031,100%], d[0.000,0.000], g[13.248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">308, c[0.020,100%], d[0.004,0.001], g[12.149]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">309, c[0.087,96%], d[0.001,0.000], g[12.838]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">310, c[0.066,98%], d[0.000,0.000], g[12.087]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">311, c[0.036,100%], d[0.000,0.000], g[11.740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">312, c[0.008,100%], d[0.000,0.001], g[11.368]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">313, c[0.094,96%], d[0.000,0.001], g[11.998]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">314, c[0.020,100%], d[0.000,0.000], g[12.739]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">315, c[0.201,94%], d[0.000,0.006], g[13.712]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">316, c[0.040,98%], d[0.000,0.000], g[14.252]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">317, c[0.029,100%], d[0.000,0.000], g[14.002]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">318, c[0.046,98%], d[0.000,0.000], g[13.822]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">319, c[0.043,98%], d[0.001,0.000], g[14.275]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">320, c[0.014,100%], d[0.005,0.000], g[13.443]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">321, c[0.014,100%], d[0.000,0.001], g[13.228]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">322, c[0.054,98%], d[0.000,0.000], g[12.922]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">323, c[0.058,96%], d[0.000,0.000], g[13.601]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">324, c[0.013,100%], d[0.000,0.001], g[13.480]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">325, c[0.009,100%], d[0.000,0.000], g[13.472]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">326, c[0.006,100%], d[0.000,0.000], g[13.815]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">327, c[0.007,100%], d[0.000,0.000], g[13.085]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">328, c[0.009,100%], d[0.000,0.000], g[13.497]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">329, c[0.009,100%], d[0.000,0.000], g[13.333]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">330, c[0.019,100%], d[0.000,0.000], g[13.375]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">331, c[0.016,100%], d[0.000,0.000], g[13.675]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">332, c[0.008,100%], d[0.001,0.001], g[13.515]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">333, c[0.010,100%], d[0.002,0.000], g[13.505]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">334, c[0.013,100%], d[0.000,0.000], g[13.200]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">335, c[0.017,100%], d[0.000,0.000], g[12.966]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">336, c[0.013,100%], d[0.000,0.000], g[13.274]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">337, c[0.013,100%], d[0.000,0.000], g[13.493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">338, c[0.008,100%], d[0.000,0.000], g[13.660]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">339, c[0.020,100%], d[0.000,0.000], g[13.632]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">340, c[0.060,96%], d[0.002,0.000], g[13.148]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">341, c[0.017,100%], d[0.000,0.000], g[13.061]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">342, c[0.111,94%], d[0.000,0.081], g[15.259]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">343, c[0.054,98%], d[0.026,0.000], g[15.226]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">344, c[0.404,90%], d[0.117,0.000], g[12.710]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">345, c[0.149,92%], d[0.393,0.001], g[0.460]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">346, c[4.349,54%], d[0.074,0.080], g[11.147]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">347, c[1.700,60%], d[0.094,0.935], g[2.091]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">348, c[4.089,50%], d[0.000,0.434], g[15.235]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">349, c[2.323,52%], d[0.925,0.000], g[14.946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">350, c[1.620,62%], d[0.000,0.000], g[15.020]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">351, c[3.079,36%], d[0.001,0.000], g[14.589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">352, c[1.501,70%], d[0.004,0.001], g[14.565]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">353, c[1.048,62%], d[0.158,0.000], g[13.747]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">354, c[1.235,64%], d[0.008,0.005], g[13.788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">355, c[0.671,70%], d[0.013,0.000], g[13.756]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">356, c[0.452,82%], d[0.017,0.000], g[13.773]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">357, c[0.430,86%], d[0.003,0.000], g[13.757]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">358, c[0.583,78%], d[0.004,0.000], g[14.327]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">359, c[0.309,92%], d[0.023,0.000], g[13.001]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">360, c[0.464,78%], d[0.001,0.000], g[13.276]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">361, c[0.491,78%], d[0.001,0.000], g[13.509]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">362, c[0.371,82%], d[0.015,0.000], g[12.071]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">363, c[0.561,76%], d[0.001,0.023], g[12.940]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">364, c[0.257,94%], d[0.000,0.000], g[13.370]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">365, c[0.268,90%], d[0.005,0.000], g[12.821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">366, c[0.305,92%], d[0.002,0.000], g[12.609]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">367, c[0.193,96%], d[0.000,0.000], g[13.010]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">368, c[0.183,92%], d[0.000,0.000], g[12.936]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">369, c[0.193,90%], d[0.118,0.000], g[9.377]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">370, c[0.269,90%], d[0.001,0.002], g[9.601]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">371, c[0.188,94%], d[0.000,0.001], g[10.282]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">372, c[0.126,96%], d[0.000,0.000], g[11.443]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">373, c[0.141,96%], d[0.000,0.000], g[10.879]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">374, c[0.142,94%], d[0.000,0.002], g[11.711]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">375, c[0.106,98%], d[0.001,0.003], g[11.233]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">376, c[0.069,98%], d[0.001,0.000], g[11.312]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">377, c[0.107,98%], d[0.001,0.001], g[12.332]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">378, c[0.080,100%], d[0.001,0.001], g[12.943]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">379, c[0.056,98%], d[0.000,0.001], g[12.833]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">380, c[0.065,98%], d[0.000,0.002], g[13.572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">381, c[0.102,96%], d[0.000,0.000], g[14.138]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">382, c[0.062,98%], d[0.000,0.000], g[13.466]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">383, c[0.066,98%], d[0.000,0.000], g[13.962]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">384, c[0.042,100%], d[0.024,0.000], g[11.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">385, c[0.219,92%], d[0.000,0.007], g[13.291]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">386, c[0.155,96%], d[0.001,0.000], g[13.303]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">387, c[0.161,94%], d[0.000,0.000], g[12.160]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">388, c[0.198,96%], d[0.000,0.001], g[11.724]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">389, c[0.079,98%], d[0.001,0.000], g[13.004]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">390, c[0.063,98%], d[0.001,0.000], g[13.175]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">391, c[0.067,98%], d[0.001,0.000], g[13.619]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">392, c[0.060,98%], d[0.002,0.000], g[13.492]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">393, c[0.036,100%], d[0.000,0.000], g[13.525]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">394, c[0.042,100%], d[0.000,0.000], g[13.463]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">395, c[0.022,100%], d[0.000,0.000], g[13.720]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">396, c[0.053,100%], d[0.000,0.000], g[13.826]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">397, c[0.027,100%], d[0.000,0.001], g[13.839]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">398, c[0.034,100%], d[0.000,0.000], g[14.349]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">399, c[0.049,98%], d[0.000,0.000], g[13.516]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">400, c[0.087,98%], d[0.000,0.000], g[13.474]\n",
      "Classifier Accuracy: 92.151%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      ">401, c[0.037,100%], d[0.000,0.000], g[13.863]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">402, c[0.021,100%], d[0.000,0.000], g[14.306]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">403, c[0.046,98%], d[0.000,0.000], g[13.968]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">404, c[0.049,100%], d[0.000,0.000], g[14.159]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">405, c[0.034,100%], d[0.000,0.000], g[14.111]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">406, c[0.060,96%], d[0.001,0.000], g[14.086]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">407, c[0.054,98%], d[0.000,0.000], g[14.487]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">408, c[0.034,100%], d[0.000,0.000], g[14.615]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">409, c[0.013,100%], d[0.000,0.000], g[14.602]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">410, c[0.058,98%], d[0.000,0.000], g[14.107]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">411, c[0.046,100%], d[0.004,0.000], g[13.678]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">412, c[0.025,100%], d[0.000,0.000], g[13.622]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">413, c[0.026,100%], d[0.000,0.000], g[14.334]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">414, c[0.040,98%], d[0.000,0.000], g[14.071]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">415, c[0.033,100%], d[0.000,0.001], g[13.909]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">416, c[0.014,100%], d[0.000,0.014], g[14.686]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">417, c[0.023,100%], d[0.000,0.000], g[15.012]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">418, c[0.019,100%], d[0.000,0.000], g[14.949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">419, c[0.012,100%], d[0.000,0.000], g[15.075]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">420, c[0.014,100%], d[0.001,0.000], g[14.967]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">421, c[0.031,100%], d[0.001,0.000], g[14.800]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">422, c[0.027,100%], d[0.000,0.000], g[14.953]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">423, c[0.085,98%], d[0.000,0.000], g[14.905]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">424, c[0.071,98%], d[0.000,0.000], g[14.788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">425, c[0.009,100%], d[0.000,0.000], g[15.051]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">426, c[0.018,100%], d[0.001,0.000], g[14.987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">427, c[0.012,100%], d[0.000,0.000], g[14.943]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">428, c[0.006,100%], d[0.000,0.000], g[14.795]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">429, c[0.020,100%], d[0.000,0.000], g[14.931]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">430, c[0.009,100%], d[0.000,0.000], g[14.612]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">431, c[0.014,100%], d[0.000,0.000], g[14.953]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">432, c[0.027,100%], d[0.000,0.000], g[14.986]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">433, c[0.018,100%], d[0.000,0.000], g[15.032]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">434, c[0.006,100%], d[0.001,0.000], g[14.966]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">435, c[0.020,100%], d[0.001,0.000], g[14.766]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">436, c[0.020,100%], d[0.000,0.000], g[14.749]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">437, c[0.015,100%], d[0.000,0.000], g[14.632]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">438, c[0.018,100%], d[0.000,0.000], g[14.956]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">439, c[0.007,100%], d[0.000,0.000], g[14.473]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">440, c[0.019,100%], d[0.000,0.000], g[14.823]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">441, c[0.016,100%], d[0.000,0.000], g[14.879]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">442, c[0.010,100%], d[0.000,0.000], g[14.813]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">443, c[0.032,98%], d[0.000,0.000], g[14.741]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">444, c[0.008,100%], d[0.000,0.000], g[14.628]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">445, c[0.012,100%], d[0.003,0.000], g[14.623]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">446, c[0.025,100%], d[0.000,0.000], g[14.736]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">447, c[0.005,100%], d[0.000,0.000], g[14.870]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">448, c[0.012,100%], d[0.000,0.000], g[14.850]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">449, c[0.012,100%], d[0.000,0.000], g[14.773]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">450, c[0.017,100%], d[0.000,0.000], g[14.740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">451, c[0.027,98%], d[0.000,0.000], g[14.468]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">452, c[0.023,100%], d[0.000,0.000], g[14.586]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">453, c[0.011,100%], d[0.000,0.000], g[14.706]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">454, c[0.004,100%], d[0.000,0.001], g[14.490]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">455, c[0.006,100%], d[0.000,0.000], g[14.967]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">456, c[0.009,100%], d[0.000,0.001], g[15.190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">457, c[0.005,100%], d[0.000,0.000], g[14.970]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">458, c[0.005,100%], d[0.000,0.000], g[14.739]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">459, c[0.005,100%], d[0.000,0.000], g[15.024]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">460, c[0.008,100%], d[0.000,0.000], g[15.127]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">461, c[0.008,100%], d[0.000,0.000], g[14.982]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">462, c[0.006,100%], d[0.003,0.000], g[15.193]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">463, c[0.019,100%], d[0.000,0.000], g[15.009]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">464, c[0.020,100%], d[0.000,0.000], g[14.720]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">465, c[0.021,100%], d[0.000,0.001], g[15.107]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">466, c[0.018,100%], d[0.000,0.000], g[14.676]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">467, c[0.007,100%], d[0.000,0.000], g[14.998]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">468, c[0.007,100%], d[0.000,0.000], g[15.067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">469, c[0.011,100%], d[0.000,0.000], g[14.898]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">470, c[0.014,100%], d[0.000,0.000], g[14.825]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">471, c[0.011,100%], d[0.000,0.000], g[14.625]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">472, c[0.005,100%], d[0.000,0.000], g[15.081]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">473, c[0.015,100%], d[0.000,0.000], g[15.055]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">474, c[0.003,100%], d[0.001,0.000], g[14.733]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">475, c[0.003,100%], d[0.000,0.000], g[14.843]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">476, c[0.017,100%], d[0.000,0.000], g[14.987]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">477, c[0.010,100%], d[0.000,0.000], g[15.025]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">478, c[0.011,100%], d[0.000,0.000], g[14.904]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">479, c[0.004,100%], d[0.000,0.000], g[14.913]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">480, c[0.010,100%], d[0.000,0.000], g[14.847]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">481, c[0.006,100%], d[0.000,0.000], g[15.171]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">482, c[0.006,100%], d[0.000,0.000], g[14.935]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">483, c[0.003,100%], d[0.000,0.000], g[14.868]\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">484, c[0.002,100%], d[0.000,0.000], g[15.083]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">485, c[0.015,100%], d[0.000,0.000], g[14.895]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">486, c[0.006,100%], d[0.000,0.000], g[14.987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">487, c[0.014,100%], d[0.000,0.000], g[15.035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">488, c[0.003,100%], d[0.000,0.000], g[14.884]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">489, c[0.013,100%], d[0.000,0.000], g[14.821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">490, c[0.033,98%], d[0.000,0.000], g[15.027]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">491, c[0.006,100%], d[0.000,0.000], g[15.035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">492, c[0.008,100%], d[0.000,0.000], g[14.980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">493, c[0.007,100%], d[0.000,0.000], g[15.082]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">494, c[0.004,100%], d[0.000,0.000], g[14.946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">495, c[0.002,100%], d[0.000,0.002], g[15.023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">496, c[0.005,100%], d[0.000,0.000], g[15.309]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">497, c[0.003,100%], d[0.000,0.000], g[14.997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">498, c[0.003,100%], d[0.001,0.000], g[14.937]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">499, c[0.007,100%], d[0.000,0.000], g[15.128]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">500, c[0.001,100%], d[0.000,0.000], g[15.013]\n",
      "Classifier Accuracy: 94.108%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">501, c[0.001,100%], d[0.000,0.000], g[15.142]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">502, c[0.006,100%], d[0.000,0.000], g[14.927]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">503, c[0.002,100%], d[0.000,0.000], g[14.812]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">504, c[0.004,100%], d[0.000,0.000], g[14.810]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">505, c[0.002,100%], d[0.000,0.000], g[15.187]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">506, c[0.006,100%], d[0.000,0.000], g[14.896]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">507, c[0.008,100%], d[0.000,0.000], g[14.980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">508, c[0.004,100%], d[0.001,0.000], g[15.117]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">509, c[0.034,98%], d[0.000,0.000], g[14.985]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">510, c[0.019,100%], d[0.000,0.000], g[15.031]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">511, c[0.021,98%], d[0.001,0.000], g[15.107]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">512, c[0.032,98%], d[0.000,0.000], g[15.036]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">513, c[0.042,98%], d[0.000,0.000], g[14.988]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">514, c[0.027,98%], d[0.000,0.000], g[14.913]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">515, c[0.009,100%], d[0.000,0.000], g[14.974]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">516, c[0.006,100%], d[0.000,0.000], g[14.925]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">517, c[0.008,100%], d[0.000,0.000], g[14.897]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">518, c[0.005,100%], d[0.000,0.000], g[15.083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">519, c[0.004,100%], d[0.000,0.000], g[14.926]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">520, c[0.002,100%], d[0.000,0.000], g[15.176]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">521, c[0.003,100%], d[0.002,0.000], g[14.748]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">522, c[0.001,100%], d[0.000,0.000], g[15.165]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">523, c[0.003,100%], d[0.000,0.000], g[15.038]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">524, c[0.005,100%], d[0.000,0.000], g[14.949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">525, c[0.001,100%], d[0.000,0.000], g[15.029]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">526, c[0.008,100%], d[0.000,0.000], g[14.985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">527, c[0.003,100%], d[0.000,0.000], g[14.997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">528, c[0.005,100%], d[0.000,0.000], g[14.990]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">529, c[0.003,100%], d[0.000,0.000], g[15.103]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">530, c[0.004,100%], d[0.000,0.000], g[15.137]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">531, c[0.002,100%], d[0.000,0.000], g[14.996]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">532, c[0.008,100%], d[0.000,0.000], g[15.060]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">533, c[0.004,100%], d[0.000,0.000], g[15.061]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">534, c[0.004,100%], d[0.000,0.000], g[15.142]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">535, c[0.001,100%], d[0.000,0.000], g[15.001]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">536, c[0.000,100%], d[0.000,0.000], g[14.785]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">537, c[0.004,100%], d[0.000,0.000], g[14.792]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">538, c[0.002,100%], d[0.000,0.000], g[14.844]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">539, c[0.020,100%], d[0.000,0.000], g[15.162]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">540, c[0.007,100%], d[0.000,0.000], g[15.138]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">541, c[0.010,100%], d[0.000,0.000], g[14.969]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">542, c[0.011,100%], d[0.000,0.000], g[15.111]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">543, c[0.024,100%], d[0.000,0.000], g[14.889]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">544, c[0.003,100%], d[0.000,0.000], g[14.831]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">545, c[0.016,100%], d[0.000,0.000], g[14.718]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">546, c[0.005,100%], d[0.000,0.000], g[15.031]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">547, c[0.006,100%], d[0.000,0.000], g[14.899]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">548, c[0.026,98%], d[0.000,0.000], g[15.013]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">549, c[0.001,100%], d[0.000,0.000], g[15.018]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">550, c[0.015,100%], d[0.000,0.000], g[15.230]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">551, c[0.038,98%], d[0.000,0.001], g[14.946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">552, c[0.004,100%], d[0.000,0.000], g[15.118]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">553, c[0.022,98%], d[0.000,0.000], g[15.206]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">554, c[0.044,98%], d[0.000,0.000], g[15.125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">555, c[0.002,100%], d[0.000,0.000], g[15.355]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">556, c[0.003,100%], d[0.000,0.000], g[15.193]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">557, c[0.040,98%], d[0.000,0.000], g[15.246]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">558, c[0.002,100%], d[0.000,0.000], g[15.136]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">559, c[0.034,98%], d[0.000,0.000], g[15.287]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">560, c[0.007,100%], d[0.000,0.000], g[15.120]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">561, c[0.008,100%], d[0.000,0.000], g[15.000]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">562, c[0.002,100%], d[0.000,0.000], g[14.929]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">563, c[0.021,98%], d[0.000,0.000], g[15.152]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">564, c[0.009,100%], d[0.000,0.000], g[15.228]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">565, c[0.015,100%], d[0.002,0.000], g[15.042]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">566, c[0.002,100%], d[0.000,0.002], g[14.647]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">567, c[0.007,100%], d[0.000,0.000], g[15.132]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">568, c[0.006,100%], d[0.000,0.000], g[15.248]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">569, c[0.004,100%], d[0.000,0.000], g[15.101]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">570, c[0.006,100%], d[0.000,0.000], g[14.837]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">571, c[0.003,100%], d[0.000,0.000], g[14.995]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">572, c[0.004,100%], d[0.000,0.000], g[15.073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">573, c[0.003,100%], d[0.000,0.000], g[15.031]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">574, c[0.002,100%], d[0.000,0.000], g[15.068]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">575, c[0.004,100%], d[0.000,0.000], g[15.119]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">576, c[0.004,100%], d[0.000,0.000], g[14.756]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      ">577, c[0.003,100%], d[0.000,0.000], g[15.017]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">578, c[0.008,100%], d[0.000,0.000], g[15.083]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">579, c[0.010,100%], d[0.000,0.000], g[15.174]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">580, c[0.002,100%], d[0.000,0.000], g[15.241]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">581, c[0.008,100%], d[0.000,0.000], g[14.945]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">582, c[0.005,100%], d[0.000,0.000], g[14.884]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">583, c[0.005,100%], d[0.000,0.000], g[14.812]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">584, c[0.001,100%], d[0.000,0.000], g[15.090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">585, c[0.002,100%], d[0.000,0.000], g[14.904]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">586, c[0.001,100%], d[0.000,0.000], g[15.045]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">587, c[0.002,100%], d[0.000,0.000], g[14.850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">588, c[0.002,100%], d[0.000,0.000], g[15.110]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">589, c[0.001,100%], d[0.000,0.000], g[15.275]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">590, c[0.007,100%], d[0.000,0.000], g[15.169]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">591, c[0.004,100%], d[0.000,0.000], g[14.861]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">592, c[0.002,100%], d[0.000,0.000], g[14.992]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">593, c[0.025,98%], d[0.000,0.000], g[14.990]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">594, c[0.005,100%], d[0.000,0.000], g[15.117]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">595, c[0.005,100%], d[0.000,0.000], g[14.979]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">596, c[0.008,100%], d[0.000,0.000], g[15.055]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">597, c[0.002,100%], d[0.000,0.000], g[14.584]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">598, c[0.001,100%], d[0.000,0.000], g[15.238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">599, c[0.002,100%], d[0.000,0.000], g[14.664]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">600, c[0.001,100%], d[0.001,0.000], g[14.956]\n",
      "Classifier Accuracy: 94.360%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">601, c[0.007,100%], d[0.000,0.000], g[15.192]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">602, c[0.003,100%], d[0.000,0.000], g[15.048]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      ">603, c[0.001,100%], d[0.000,0.000], g[14.876]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">604, c[0.001,100%], d[0.000,0.000], g[15.056]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">605, c[0.003,100%], d[0.000,0.000], g[15.227]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">606, c[0.003,100%], d[0.000,0.000], g[15.131]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">607, c[0.003,100%], d[0.000,0.000], g[15.047]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">608, c[0.001,100%], d[0.000,0.000], g[14.814]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">609, c[0.001,100%], d[0.000,0.000], g[14.979]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">610, c[0.001,100%], d[0.000,0.000], g[14.984]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">611, c[0.001,100%], d[0.000,0.000], g[14.701]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">612, c[0.001,100%], d[0.000,0.000], g[15.188]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">613, c[0.003,100%], d[0.000,0.000], g[15.056]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">614, c[0.001,100%], d[0.000,0.000], g[15.075]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">615, c[0.001,100%], d[0.000,0.000], g[14.819]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">616, c[0.001,100%], d[0.000,0.000], g[15.119]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">617, c[0.007,100%], d[0.000,0.000], g[14.913]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">618, c[0.002,100%], d[0.000,0.000], g[14.699]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">619, c[0.001,100%], d[0.000,0.000], g[15.000]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">620, c[0.002,100%], d[0.000,0.000], g[14.985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">621, c[0.004,100%], d[0.000,0.000], g[15.141]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">622, c[0.003,100%], d[0.000,0.000], g[14.989]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">623, c[0.003,100%], d[0.000,0.000], g[15.041]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">624, c[0.006,100%], d[0.000,0.000], g[15.010]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">625, c[0.002,100%], d[0.000,0.000], g[15.055]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">626, c[0.000,100%], d[0.000,0.000], g[15.070]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">627, c[0.001,100%], d[0.000,0.000], g[14.936]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">628, c[0.002,100%], d[0.000,0.091], g[15.259]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">629, c[0.002,100%], d[0.000,0.000], g[15.070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">630, c[0.002,100%], d[0.000,0.000], g[15.337]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">631, c[0.005,100%], d[0.000,0.000], g[15.161]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">632, c[0.009,100%], d[0.011,0.000], g[15.020]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">633, c[0.094,96%], d[0.009,0.000], g[15.256]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">634, c[0.038,98%], d[0.000,0.000], g[15.130]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">635, c[0.352,90%], d[0.000,0.000], g[14.442]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">636, c[2.256,72%], d[0.053,0.000], g[14.102]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">637, c[1.597,80%], d[0.000,0.000], g[14.216]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">638, c[1.222,74%], d[0.000,0.001], g[12.427]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">639, c[2.508,70%], d[0.000,0.002], g[13.740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">640, c[2.058,62%], d[0.000,0.013], g[13.987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">641, c[0.225,92%], d[0.032,0.002], g[11.588]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">642, c[0.748,76%], d[0.000,0.003], g[11.000]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">643, c[0.502,86%], d[0.000,0.015], g[15.064]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">644, c[0.335,84%], d[0.000,0.000], g[15.081]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">645, c[0.146,98%], d[0.000,0.000], g[15.166]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">646, c[0.178,88%], d[0.000,0.000], g[15.091]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">647, c[0.201,92%], d[0.000,0.000], g[15.216]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">648, c[0.041,100%], d[0.000,0.000], g[14.757]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">649, c[0.028,100%], d[0.000,0.000], g[14.976]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">650, c[0.052,100%], d[0.010,0.000], g[14.690]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">651, c[0.049,100%], d[0.000,0.000], g[14.637]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">652, c[0.023,100%], d[0.000,0.000], g[14.780]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">653, c[0.017,100%], d[0.000,0.000], g[14.748]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">654, c[0.038,100%], d[0.000,0.000], g[14.850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">655, c[0.027,100%], d[0.000,0.000], g[14.746]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">656, c[0.050,98%], d[0.000,0.000], g[14.980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">657, c[0.076,98%], d[0.000,0.000], g[15.013]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">658, c[0.040,100%], d[0.000,0.000], g[14.958]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">659, c[0.077,98%], d[0.000,0.000], g[14.532]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">660, c[0.040,100%], d[0.000,0.000], g[14.515]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">661, c[0.012,100%], d[0.000,0.000], g[14.854]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">662, c[0.034,98%], d[0.000,0.000], g[14.496]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">663, c[0.028,100%], d[0.000,0.000], g[14.497]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">664, c[0.017,100%], d[0.000,0.000], g[14.297]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">665, c[0.010,100%], d[0.000,0.000], g[14.612]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">666, c[0.026,100%], d[0.001,0.000], g[14.614]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">667, c[0.053,98%], d[0.000,0.000], g[14.498]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">668, c[0.008,100%], d[0.000,0.000], g[14.600]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">669, c[0.020,100%], d[0.000,0.000], g[14.383]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">670, c[0.015,100%], d[0.000,0.000], g[14.028]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">671, c[0.024,100%], d[0.000,0.000], g[14.572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">672, c[0.013,100%], d[0.000,0.000], g[14.468]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">673, c[0.019,100%], d[0.000,0.000], g[14.662]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">674, c[0.011,100%], d[0.000,0.000], g[14.280]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">675, c[0.017,100%], d[0.000,0.000], g[14.637]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">676, c[0.011,100%], d[0.000,0.000], g[14.343]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">677, c[0.011,100%], d[0.000,0.000], g[14.640]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">678, c[0.011,100%], d[0.000,0.000], g[14.585]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">679, c[0.011,100%], d[0.000,0.000], g[14.719]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">680, c[0.012,100%], d[0.000,0.000], g[14.398]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">681, c[0.006,100%], d[0.000,0.000], g[14.417]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">682, c[0.013,100%], d[0.000,0.000], g[14.698]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">683, c[0.021,100%], d[0.000,0.000], g[14.322]\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">684, c[0.008,100%], d[0.000,0.000], g[14.125]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">685, c[0.008,100%], d[0.000,0.000], g[14.942]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">686, c[0.013,100%], d[0.000,0.000], g[14.621]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">687, c[0.012,100%], d[0.000,0.000], g[14.475]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">688, c[0.016,100%], d[0.000,0.000], g[14.218]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">689, c[0.005,100%], d[0.000,0.000], g[14.271]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">690, c[0.008,100%], d[0.000,0.000], g[14.536]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">691, c[0.007,100%], d[0.000,0.000], g[14.465]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">692, c[0.006,100%], d[0.000,0.000], g[14.116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">693, c[0.013,100%], d[0.000,0.000], g[14.766]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">694, c[0.005,100%], d[0.000,0.000], g[14.722]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">695, c[0.005,100%], d[0.000,0.000], g[14.678]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">696, c[0.014,100%], d[0.000,0.000], g[14.367]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">697, c[0.011,100%], d[0.000,0.001], g[14.463]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">698, c[0.009,100%], d[0.000,0.000], g[14.753]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">699, c[0.005,100%], d[0.000,0.000], g[14.187]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">700, c[0.005,100%], d[0.000,0.000], g[14.495]\n",
      "Classifier Accuracy: 94.444%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">701, c[0.013,100%], d[0.003,0.000], g[14.590]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">702, c[0.008,100%], d[0.000,0.000], g[14.399]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">703, c[0.021,100%], d[0.000,0.008], g[14.562]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">704, c[0.012,100%], d[0.000,0.000], g[14.552]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">705, c[0.006,100%], d[0.000,0.000], g[14.872]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">706, c[0.009,100%], d[0.000,0.000], g[15.003]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">707, c[0.005,100%], d[0.000,0.000], g[14.499]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">708, c[0.005,100%], d[0.000,0.000], g[14.710]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">709, c[0.004,100%], d[0.003,0.000], g[14.489]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">710, c[0.003,100%], d[0.000,0.000], g[14.619]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">711, c[0.026,100%], d[0.000,0.000], g[14.616]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">712, c[0.007,100%], d[0.000,0.000], g[14.934]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">713, c[0.003,100%], d[0.000,0.000], g[14.703]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">714, c[0.004,100%], d[0.000,0.000], g[14.700]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">715, c[0.008,100%], d[0.000,0.000], g[14.615]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">716, c[0.003,100%], d[0.000,0.000], g[14.736]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">717, c[0.006,100%], d[0.000,0.000], g[14.428]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">718, c[0.002,100%], d[0.000,0.000], g[14.860]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">719, c[0.006,100%], d[0.000,0.000], g[14.899]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">720, c[0.003,100%], d[0.000,0.000], g[15.043]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">721, c[0.003,100%], d[0.000,0.000], g[14.744]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">722, c[0.007,100%], d[0.000,0.000], g[14.852]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">723, c[0.006,100%], d[0.000,0.000], g[14.889]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">724, c[0.009,100%], d[0.000,0.000], g[14.658]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">725, c[0.005,100%], d[0.000,0.000], g[14.764]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">726, c[0.003,100%], d[0.000,0.000], g[14.776]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">727, c[0.002,100%], d[0.000,0.000], g[14.878]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">728, c[0.004,100%], d[0.000,0.000], g[14.806]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">729, c[0.005,100%], d[0.000,0.000], g[14.808]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">730, c[0.004,100%], d[0.000,0.000], g[14.860]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">731, c[0.002,100%], d[0.000,0.000], g[14.773]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">732, c[0.013,100%], d[0.000,0.000], g[15.040]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">733, c[0.005,100%], d[0.000,0.000], g[14.911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">734, c[0.005,100%], d[0.000,0.000], g[14.911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">735, c[0.007,100%], d[0.000,0.000], g[14.951]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">736, c[0.003,100%], d[0.000,0.000], g[14.922]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">737, c[0.006,100%], d[0.000,0.000], g[14.842]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">738, c[0.006,100%], d[0.000,0.000], g[15.011]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">739, c[0.007,100%], d[0.000,0.000], g[14.821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">740, c[0.002,100%], d[0.000,0.000], g[14.780]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">741, c[0.010,100%], d[0.000,0.000], g[14.534]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">742, c[0.004,100%], d[0.000,0.000], g[14.850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">743, c[0.002,100%], d[0.000,0.000], g[14.470]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">744, c[0.002,100%], d[0.000,0.000], g[14.522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">745, c[0.003,100%], d[0.000,0.000], g[14.892]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">746, c[0.004,100%], d[0.000,0.000], g[14.845]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">747, c[0.005,100%], d[0.000,0.000], g[14.939]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">748, c[0.009,100%], d[0.000,0.000], g[14.677]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">749, c[0.004,100%], d[0.000,0.000], g[14.583]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">750, c[0.006,100%], d[0.000,0.000], g[14.663]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">751, c[0.009,100%], d[0.000,0.000], g[14.947]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">752, c[0.004,100%], d[0.000,0.000], g[14.815]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">753, c[0.008,100%], d[0.000,0.000], g[14.985]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">754, c[0.002,100%], d[0.000,0.000], g[14.987]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">755, c[0.002,100%], d[0.000,0.000], g[14.964]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">756, c[0.003,100%], d[0.000,0.000], g[14.965]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">757, c[0.001,100%], d[0.000,0.000], g[14.776]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">758, c[0.011,100%], d[0.000,0.000], g[14.951]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">759, c[0.001,100%], d[0.000,0.000], g[15.166]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">760, c[0.002,100%], d[0.000,0.000], g[14.776]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">761, c[0.001,100%], d[0.000,0.000], g[14.824]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">762, c[0.032,98%], d[0.000,0.000], g[14.906]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">763, c[0.001,100%], d[0.000,0.000], g[15.077]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">764, c[0.005,100%], d[0.000,0.000], g[14.882]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">765, c[0.003,100%], d[0.000,0.000], g[14.629]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">766, c[0.003,100%], d[0.000,0.000], g[14.982]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">767, c[0.001,100%], d[0.000,0.000], g[15.057]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">768, c[0.003,100%], d[0.000,0.000], g[15.036]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">769, c[0.006,100%], d[0.000,0.000], g[14.983]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">770, c[0.004,100%], d[0.000,0.000], g[14.795]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">771, c[0.011,100%], d[0.000,0.003], g[14.984]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">772, c[0.001,100%], d[0.000,0.000], g[14.909]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">773, c[0.001,100%], d[0.000,0.000], g[14.801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">774, c[0.007,100%], d[0.000,0.000], g[15.213]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      ">775, c[0.003,100%], d[0.013,0.000], g[14.645]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">776, c[0.003,100%], d[0.000,0.000], g[14.928]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">777, c[0.008,100%], d[0.000,0.000], g[14.891]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">778, c[0.003,100%], d[0.000,0.000], g[14.863]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">779, c[0.010,100%], d[0.000,0.000], g[14.709]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">780, c[0.003,100%], d[0.000,0.000], g[14.774]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">781, c[0.002,100%], d[0.000,0.000], g[14.593]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">782, c[0.003,100%], d[0.000,0.000], g[14.836]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">783, c[0.003,100%], d[0.000,0.002], g[14.623]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">784, c[0.003,100%], d[0.000,0.000], g[14.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">785, c[0.005,100%], d[0.000,0.000], g[14.666]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">786, c[0.012,100%], d[0.000,0.000], g[15.143]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">787, c[0.001,100%], d[0.000,0.000], g[14.860]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">788, c[0.002,100%], d[0.000,0.000], g[14.658]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">789, c[0.003,100%], d[0.000,0.000], g[15.050]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">790, c[0.002,100%], d[0.000,0.000], g[14.832]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">791, c[0.008,100%], d[0.000,0.000], g[14.679]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">792, c[0.004,100%], d[0.000,0.000], g[14.384]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">793, c[0.004,100%], d[0.000,0.001], g[14.889]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">794, c[0.003,100%], d[0.000,0.000], g[14.903]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">795, c[0.001,100%], d[0.000,0.000], g[14.542]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">796, c[0.004,100%], d[0.000,0.000], g[14.759]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">797, c[0.002,100%], d[0.000,0.000], g[14.547]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">798, c[0.005,100%], d[0.000,0.000], g[14.934]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">799, c[0.012,100%], d[0.000,0.000], g[14.933]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">800, c[0.001,100%], d[0.000,0.000], g[14.889]\n",
      "Classifier Accuracy: 94.318%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">801, c[0.001,100%], d[0.000,0.000], g[14.819]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">802, c[0.003,100%], d[0.000,0.000], g[14.893]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">803, c[0.002,100%], d[0.000,0.000], g[14.998]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">804, c[0.001,100%], d[0.000,0.007], g[15.141]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">805, c[0.003,100%], d[0.000,0.000], g[15.012]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">806, c[0.006,100%], d[0.000,0.000], g[15.229]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">807, c[0.002,100%], d[0.000,0.000], g[14.870]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">808, c[0.006,100%], d[0.000,0.000], g[15.099]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">809, c[0.002,100%], d[0.000,0.000], g[14.843]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">810, c[0.001,100%], d[0.000,0.000], g[15.085]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">811, c[0.003,100%], d[0.000,0.000], g[15.055]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">812, c[0.002,100%], d[0.000,0.000], g[15.046]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">813, c[0.002,100%], d[0.000,0.000], g[15.004]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">814, c[0.002,100%], d[0.000,0.000], g[14.539]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">815, c[0.004,100%], d[0.000,0.000], g[14.997]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">816, c[0.003,100%], d[0.000,0.000], g[14.928]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">817, c[0.002,100%], d[0.000,0.000], g[15.112]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">818, c[0.003,100%], d[0.000,0.000], g[15.021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">819, c[0.001,100%], d[0.000,0.000], g[14.906]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">820, c[0.002,100%], d[0.000,0.000], g[14.836]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">821, c[0.004,100%], d[0.000,0.000], g[15.013]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">822, c[0.008,100%], d[0.000,0.000], g[15.118]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">823, c[0.003,100%], d[0.000,0.000], g[14.978]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">824, c[0.015,100%], d[0.000,0.000], g[15.085]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">825, c[0.009,100%], d[0.000,0.000], g[14.836]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">826, c[0.001,100%], d[0.000,0.000], g[14.838]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">827, c[0.003,100%], d[0.000,0.000], g[14.630]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">828, c[0.001,100%], d[0.000,0.000], g[14.899]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">829, c[0.094,98%], d[0.000,0.000], g[14.741]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">830, c[0.001,100%], d[0.000,0.000], g[14.989]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">831, c[0.008,100%], d[0.000,0.000], g[15.041]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">832, c[0.007,100%], d[0.000,0.000], g[14.880]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">833, c[0.003,100%], d[0.000,0.000], g[15.113]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">834, c[0.006,100%], d[0.000,0.000], g[14.954]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">835, c[0.002,100%], d[0.000,0.000], g[15.109]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">836, c[0.002,100%], d[0.000,0.000], g[14.919]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">837, c[0.003,100%], d[0.000,0.000], g[15.094]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">838, c[0.001,100%], d[0.000,0.000], g[15.067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">839, c[0.003,100%], d[0.000,0.000], g[15.003]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">840, c[0.001,100%], d[0.000,0.000], g[15.063]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">841, c[0.003,100%], d[0.000,0.000], g[15.042]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">842, c[0.001,100%], d[0.000,0.000], g[15.000]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">843, c[0.001,100%], d[0.000,0.000], g[15.194]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">844, c[0.001,100%], d[0.000,0.004], g[14.988]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">845, c[0.009,100%], d[0.000,0.000], g[15.148]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">846, c[0.000,100%], d[0.000,0.000], g[15.296]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">847, c[0.004,100%], d[0.000,0.000], g[15.139]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">848, c[0.001,100%], d[0.000,0.000], g[15.214]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">849, c[0.002,100%], d[0.000,0.000], g[15.201]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">850, c[0.002,100%], d[0.000,0.000], g[15.237]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">851, c[0.005,100%], d[0.000,0.000], g[15.263]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">852, c[0.001,100%], d[0.000,0.000], g[15.117]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">853, c[0.001,100%], d[0.000,0.000], g[15.108]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">854, c[0.004,100%], d[0.000,0.000], g[15.305]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      ">855, c[0.002,100%], d[0.000,0.000], g[15.170]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">856, c[0.000,100%], d[0.000,0.000], g[15.170]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">857, c[0.000,100%], d[0.000,0.000], g[15.128]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">858, c[0.001,100%], d[0.000,0.000], g[15.057]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">859, c[0.001,100%], d[0.000,0.000], g[15.205]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">860, c[0.002,100%], d[0.000,0.000], g[15.163]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">861, c[0.001,100%], d[0.000,0.000], g[15.045]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">862, c[0.000,100%], d[0.000,0.000], g[15.238]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">863, c[0.004,100%], d[0.000,0.000], g[15.300]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">864, c[0.000,100%], d[0.000,0.000], g[14.949]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">865, c[0.001,100%], d[0.000,0.000], g[15.129]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">866, c[0.003,100%], d[0.000,0.000], g[15.078]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">867, c[0.002,100%], d[0.000,0.000], g[15.162]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">868, c[0.002,100%], d[0.000,0.000], g[15.067]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">869, c[0.001,100%], d[0.000,0.000], g[14.879]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">870, c[0.001,100%], d[0.000,0.000], g[15.172]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">871, c[0.004,100%], d[0.000,0.000], g[15.179]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">872, c[0.005,100%], d[0.000,0.000], g[15.252]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">873, c[0.000,100%], d[0.000,0.000], g[15.184]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">874, c[0.001,100%], d[0.000,0.000], g[15.313]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">875, c[0.001,100%], d[0.000,0.000], g[15.237]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">876, c[0.002,100%], d[0.000,0.000], g[15.124]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">877, c[0.000,100%], d[0.000,0.000], g[15.355]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">878, c[0.001,100%], d[0.000,0.000], g[15.136]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">879, c[0.001,100%], d[0.000,0.000], g[15.266]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">880, c[0.003,100%], d[0.000,0.000], g[15.274]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">881, c[0.000,100%], d[0.000,0.000], g[15.107]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">882, c[0.001,100%], d[0.000,0.000], g[15.133]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">883, c[0.001,100%], d[0.000,0.000], g[15.197]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">884, c[0.001,100%], d[0.000,0.000], g[15.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      ">885, c[0.000,100%], d[0.000,0.000], g[15.056]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">886, c[0.001,100%], d[0.000,0.000], g[14.980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">887, c[0.002,100%], d[0.000,0.000], g[15.081]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">888, c[0.001,100%], d[0.000,0.000], g[15.149]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">889, c[0.001,100%], d[0.000,0.000], g[15.068]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">890, c[0.001,100%], d[0.000,0.000], g[15.135]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">891, c[0.001,100%], d[0.000,0.000], g[15.117]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">892, c[0.000,100%], d[0.000,0.000], g[15.161]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">893, c[0.004,100%], d[0.000,0.000], g[15.154]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">894, c[0.002,100%], d[0.000,0.000], g[15.018]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">895, c[0.002,100%], d[0.000,0.000], g[14.911]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">896, c[0.003,100%], d[0.000,0.000], g[15.053]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">897, c[0.003,100%], d[0.000,0.000], g[15.202]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">898, c[0.001,100%], d[0.000,0.000], g[15.036]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">899, c[0.001,100%], d[0.000,0.000], g[14.956]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">900, c[0.001,100%], d[0.000,0.000], g[15.335]\n",
      "Classifier Accuracy: 94.297%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      ">901, c[0.001,100%], d[0.000,0.000], g[15.070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">902, c[0.002,100%], d[0.000,0.000], g[15.123]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">903, c[0.001,100%], d[0.000,0.000], g[15.256]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">904, c[0.002,100%], d[0.000,0.000], g[15.203]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">905, c[0.001,100%], d[0.000,0.000], g[15.189]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">906, c[0.002,100%], d[0.000,0.000], g[15.086]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">907, c[0.000,100%], d[0.000,0.000], g[15.150]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">908, c[0.000,100%], d[0.000,0.000], g[15.280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">909, c[0.001,100%], d[0.000,0.000], g[15.336]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">910, c[0.001,100%], d[0.000,0.000], g[15.303]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">911, c[0.001,100%], d[0.000,0.000], g[15.326]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">912, c[0.001,100%], d[0.000,0.000], g[14.942]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">913, c[0.002,100%], d[0.000,0.000], g[15.331]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">914, c[0.002,100%], d[0.000,0.000], g[15.293]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">915, c[0.000,100%], d[0.000,0.000], g[15.284]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">916, c[0.000,100%], d[0.000,0.000], g[15.179]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">917, c[0.000,100%], d[0.000,0.000], g[15.353]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      ">918, c[0.001,100%], d[0.000,0.000], g[15.092]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">919, c[0.001,100%], d[0.000,0.000], g[15.354]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">920, c[0.002,100%], d[0.000,0.000], g[15.262]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">921, c[0.001,100%], d[0.000,0.000], g[15.237]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">922, c[0.000,100%], d[0.000,0.000], g[15.114]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">923, c[0.001,100%], d[0.000,0.000], g[15.254]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">924, c[0.002,100%], d[0.000,0.000], g[15.216]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">925, c[0.000,100%], d[0.000,0.000], g[15.151]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">926, c[0.001,100%], d[0.000,0.000], g[14.952]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">927, c[0.001,100%], d[0.000,0.000], g[15.248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">928, c[0.009,100%], d[0.000,0.000], g[15.316]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">929, c[0.000,100%], d[0.000,0.000], g[14.949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">930, c[0.002,100%], d[0.000,0.000], g[15.124]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">931, c[0.002,100%], d[0.000,0.000], g[15.232]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">932, c[0.000,100%], d[0.000,0.000], g[15.162]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">933, c[0.001,100%], d[0.000,0.000], g[15.172]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">934, c[0.002,100%], d[0.000,0.000], g[15.167]\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      ">935, c[0.000,100%], d[0.000,0.000], g[15.292]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">936, c[0.001,100%], d[0.000,0.000], g[15.282]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">937, c[0.001,100%], d[0.000,0.000], g[15.145]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">938, c[0.002,100%], d[0.000,0.000], g[15.274]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">939, c[0.001,100%], d[0.000,0.000], g[15.215]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">940, c[0.000,100%], d[0.000,0.000], g[15.189]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">941, c[0.001,100%], d[0.000,0.000], g[15.115]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">942, c[0.001,100%], d[0.000,0.000], g[15.054]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">943, c[0.001,100%], d[0.000,0.000], g[15.324]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">944, c[0.002,100%], d[0.000,0.000], g[15.069]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">945, c[0.001,100%], d[0.000,0.000], g[15.128]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">946, c[0.001,100%], d[0.000,0.000], g[15.179]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">947, c[0.001,100%], d[0.000,0.000], g[15.227]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">948, c[0.001,100%], d[0.000,0.000], g[15.098]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">949, c[0.006,100%], d[0.000,0.000], g[15.200]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">950, c[0.001,100%], d[0.000,0.000], g[15.220]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">951, c[0.001,100%], d[0.000,0.000], g[15.073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">952, c[0.002,100%], d[0.000,0.000], g[15.304]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">953, c[0.001,100%], d[0.000,0.000], g[15.058]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">954, c[0.001,100%], d[0.000,0.000], g[15.190]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      ">955, c[0.000,100%], d[0.000,0.000], g[15.177]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      ">956, c[0.000,100%], d[0.000,0.000], g[15.304]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(\"Trainig Start\")\n",
    "\n",
    "train(g_model, d_model, c_model, gan_model, dataset, latent_dim, acc_list)\n",
    "\n",
    "#_, test_acc = c_model.evaluate(X_test, y_test, verbose=0)\n",
    "#print('Test Accuracy: %.3f%%' % (test_acc * 100))\n",
    "\n",
    "    \n",
    "print(\"End\")\n",
    "print(\"Time: {:.1f}min\".format(((time.time() - start_time))/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b3d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0ff6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
